---
title: "Tadpole Mortality"
subtitle: "Métodos Analíticos"
editor: visual
authors:
  - "Mario Medina - 156940"
  - "José Eduardo Gutierrez - "
  - "Mariano Villafuerte - 156057"
format: 
    html:
      toc: TRUE
      embed-resources: TRUE
      theme: flatly
      lang: es
      font-size: 1.1em
      include-in-header: 
      - text: |
          <style>
            body { 
              line-height: 2; /* Adjust the value as needed */
            }
          </style>
---

```{r librerias}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE

knitr::opts_chunk$set(cache = TRUE)

# librerias ----
# library(cmdstanr)
library(coda)
library(dagitty)
library(DiagrammeR)
library(gt)
library(loo)
library(mvtnorm)
library(patchwork)
library(rethinking)
library(rstan)
library(scales)
library(shape)
library(tidyverse)
library(optimx) # NUEVA
library(kableExtra) # NUEVA

# configuracion de ggplot ----
theme_set(theme_minimal())

# cargamos los datos de reedfrogs ---
data(reedfrogs)
```

## Problema {#sec-problema}

En nuestro proyecto, utilizamos datos del estudio de Vonesh, J. R. y Bolker, B. M. (2005), el cual examina cómo las ranas de junco del este de África (Hyperolius spinigularis) adaptan sus tiempos de eclosión en respuesta a los depredadores. Este estudio original mostró que, a pesar de las expectativas, las larvas que eclosionaron temprano por presión de los depredadores no solo sobrevivieron, sino que lo hicieron mejor que las larvas de nidadas no perturbadas. Estos hallazgos sugieren que los costos y beneficios asociados con la plasticidad en la eclosión pueden no ser tan directos como se pensaba anteriormente.

Nuestro proyecto toma estos datos y resultados para construir un modelo Bayesiano jerárquico. El objetivo es profundizar en la comprensión de cómo las respuestas compensatorias de las larvas pueden alterar los compromisos tradicionalmente asociados con la plasticidad de eclosión inducida por depredadores. El modelo que desarrollamos intenta capturar la dinámica de crecimiento compensatorio y las tasas de depredación específicas de tamaño y densidad que pueden explicar mejor las altas tasas de supervivencia observadas en las larvas eclosionadas temprano. Nuestros análisis proporcionan una perspectiva más matizada sobre cómo las decisiones de eclosión temprana influyen en la supervivencia y el desarrollo posterior de las ranas, indicando que los verdaderos costos de estas decisiones emergen más adelante en la vida de las larvas.

Este enfoque modela matemáticamente las interacciones complejas y ofrece nuevas vías para entender las estrategias adaptativas en anfibios frente a amenazas ambientales.

## Datos {#sec-datos}

Utilizamos el conjunto de datos de *reedfrogs* disponible en la librería de *rethinking*. Las instrucciones para instalar la librería y cargar los datos están disponibles en el Anexo 1: *Rethinking y sus datos*.

Para este problema contamos inicialmente con 5 variables:

| Variable | Descripción                                   |
|----------|-----------------------------------------------|
| density  | Densidad inicial de renacuajos                |
| pred     | Factor indicador de presencia de depredadores |
| size     | Factor del tamaño de los renacuajos           |
| surv     | Número de renacuajos que sobrevivieron        |
| propsurv | Proporción de supervivencia                   |

El conjunto de datos cuenta con información de 48 tanques clasificados en pequeños, medianos y grandes, dependiendo de la densidad de renacuajos en cada uno. Además, disponemos de datos sobre la supervivencia y la tasa de supervivencia en cada tanque.

```{r dataframe_calc}
#| echo: FALSE
df <- reedfrogs

# Add an index column to the data frame
df <-  df %>% mutate(tank = seq(NROW(df)))
df$index <- seq.int(nrow(df))

# Calculate the mean of propsurv
mean_propsurv <- mean(df$propsurv)
```

```{r scatter1}
#| echo: FALSE
# Create the scatterplot with annotations
p <- ggplot(df, 
            aes(x = index, 
                y = propsurv)) +
  geom_point() +
  geom_hline(yintercept = mean_propsurv, 
             linetype = "dashed", 
             color = "blue4") +
  annotate("text", 
           x = max(df$index) - 23, 
           y = mean_propsurv + 0.05, 
           label = "Promedio de supervivencia en tanques", 
           color = "grey", fontface = "italic", hjust = 0) +  
  labs(x = "Tanque", y = "Tasa de Supervivencia") +
  theme(
    axis.title.x = element_text(face = "italic"),
    axis.title.y = element_text(face = "italic")) +
  scale_x_continuous(breaks = c(8, 24, 40), 
                     labels = c("1 <= Pequeño < 16", 
                                "16 <= Mediano < 32", 
                                "32 <= Grande < 48")) +
  geom_vline(xintercept = 16, 
             color = "cyan3")+
  geom_vline(xintercept = 32, 
             color = "cyan3")+
  geom_vline(xintercept = 48, 
             color = "cyan3") +
  scale_y_continuous(labels = scales::percent_format())

p
```

Hay mucha variación en estos datos. Parte de la variación proviene del tratamiento experimental, pero mucha también proviene de otras fuentes. Pensemos en cada fila como un "tanque," un entorno experimental que contiene renacuajos. Hay muchas cosas peculiares de cada tanque que no se miden, y estos factores no medidos crean variación en la supervivencia entre tanques, incluso cuando todas las variables predictoras tienen el mismo valor. Se realizan múltiples observaciones, en este caso los renacuajos, dentro de cada grupo.

Tenemos medidas repetidas y heterogeneidad entre grupos. Si ignoramos los grupos, asignando el mismo intercepto a cada uno de ellos, corremos el riesgo de ignorar una variación importante en la supervivencia. Esta variación podría enmascarar la asociación con otras variables. Si en su lugar estimamos un intercepto único para cada grupo, utilizando una variable dummy para cada tanque, estaríamos practicando una especie de amnesia. Después de todo, los tanques son diferentes, pero cada tanque nos ayuda a estimar la supervivencia en los otros tanques. Por lo tanto, no tiene sentido olvidar por completo, pasando de un tanque a otro.

## DAG

El modelo jerárquico que proponemos pretende capturar estas complejas interacciones entre la densidad, la tasa de supervivencia y otros factores clave para proporcionar una comprensión más profunda de las estrategias adaptativas de las ranas frente a las amenazas de los depredadores.

```{r dag_graph}
#| echo: FALSE
grViz("
digraph {
  graph [ranksep = 0.2, rankdir=LR]
  node [shape=plaintext]
    S
    T
    D
    G
    P
  edge [minlen = 5]
   T -> S
   D -> S
   G -> S
   P -> S
}
", width = 150, height = 60)
```

Con

-   $\textrm{T}=\textrm{Tanque}$

-   $\textrm{D}=\textrm{Densidad inicial}$

-   $\textrm{G}=\textrm{Tamaño}$

-   $\textrm{P}=\textrm{Depredadores}$

-   $\textrm{S}=\textrm{Supervivencia}$

Si bien podríamos considerar que existe alguna otra relación entre las variables, debemos considerar que los datos provienen de un experimento controlado. En otro contexto, sería correcto considerar algunas relaciones como que el tamaño de los renacuajos puede tener un efecto en la densidad; o la presencia de los depredadores en la densidad; o factores no observados como la cantidad de comida u otros recursos en el tamaño y en la densidad; o bien, factores genéticos en el tamaño de los renacuajos. Sería interesante repetir estas estimaciones en cuerpos de agua en la naturaleza, mas no en tanques controlados. Por el momento, el experimento sirve para estudiar la tasa de supervivencia en un ambiente controlado.

## Modelo Completamente Agrupado

En un primer intento, se puede considerar un modelo del estilo:

$$
S_i \sim \textrm{Binomial}(D_i,p_i)
$$

$$
\textrm{logit}(p_i) = \alpha
$$

$$
\alpha = \textrm{Normal}(0, 1.5)
$$

Lo cual se traduce en el siguiente código en Stan:

```{stan output.var="m_1"}
data {
  int<lower=0> T;         // Num de tanques
  int<lower=0> S[T];         // Num de renacuajos que sobrevivieron
  int<lower=0> D[T];         // Densidad inicial
}

parameters {
  real alpha;                // Un alpha para todos los tanques
}

model {
  // Prior de aplha
  alpha ~ normal(0, 1.5);
  
  for (t in 1:T) {
    S[t] ~ binomial(D[t], inv_logit(alpha));
  }
}

generated quantities {
  int S_rep[T]; 

  // Predicciones basadas en probabilidad comun
  for (t in 1:T) {
    S_rep[t] = binomial_rng(D[t], inv_logit(alpha));
  }
}

```

En este caso, todos los tanques comparten una misma $\alpha$ (*complete pooling*). Es decir, el modelo considera que todos los tanques tienen una misma probabilidad de supervivencia para los renacuajos. Este modelo no considera la variabilidad que pueda haber entre tanques más que la generada por la densidad inicial.

```{r ajuste_m1}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE

dat <- list(
  "T" = max(df$tank),
  S = df$surv,
  D = df$density
)

fit1 <- rstan::sampling(m_1, 
                 data = dat, 
                 iter = 1000, 
                 chains = 2, 
                 cores = 2,
                 refresh=0)
```

Podemos ver los resultados de nuestro primer modelo para la estimación de $\alpha$.

```{r print_m1_results}
#| echo: FALSE
#| warning: FALSE
#| message: FALSE

fit1_summary <- rstan::summary(fit1, 
                               probs = c(0.025,
                                         0.5,
                                         0.975))$summary 

fit1_summary |> 
  as.data.frame() |>
  rownames_to_column("parameter")  |>
  select(parameter,mean, sd, "2.5%", "50%", "97.5%", n_eff, Rhat) |>
  filter(parameter=='alpha' | parameter=='lp__')|>
  gt() |>
  fmt_number()
```

E igualmente podemos comparar nuestras predicciones contra los datos originales:

```{r predictions_m1}
#| echo: FALSE

post1 <- as.data.frame(fit1, pars = c('S_rep'))
df$urv_est <- post1 %>% colMeans
df$propsurv_est <- df$urv_est/df$density

alpha1 <- as.data.frame(fit1, pars = c('alpha')) 
alpha_est <- alpha1$alpha %>% mean() %>% plogis

# Create the scatterplot with annotations
p <- ggplot(df, 
            aes(x = index, 
                y = propsurv_est)) +
  geom_point(data=df, 
          aes(x = index, 
              y = propsurv), color='grey')+
  geom_point(color = 'blue3') +
  geom_hline(yintercept = alpha_est, 
             linetype = "dashed", 
             color = "blue4") +
  labs(x = "Tanque", 
       y = "Tasa de Supervivencia") +
  theme(
    axis.title.x = element_text(face = "italic"),
    axis.title.y = element_text(face = "italic")
  ) +
  scale_x_continuous(breaks = c(8, 24, 40), 
                     labels = c("1 <= Pequeño < 16", 
                                "16 <= Mediano < 32", 
                                "32 <= Grande < 48")) +
  geom_vline(xintercept = 16, color = "cyan3")+
  geom_vline(xintercept = 32, color = "cyan3")+
  geom_vline(xintercept = 48, color = "cyan3")+
  # ylim(0, 1) +
  scale_y_continuous(labels = scales::percent_format())

p
```

Y podemos observar que las predicciones (puntos azules) se ajustan al promedio de supervivencia en los tanques (línea punteada azul). Vemos que este modelo nos lleva a un subajuste. En gris apreciamos los datos originales.

## Modelo No Agrupado

Otra opción que tenemos es asumir que cada tanque tiene su propia $\alpha$ y que no podemos obtener información para un tanque al observar los otros tanques. De tal manera que:

$$ S_i \sim \textrm{Binomial}(D_i,p_i) $$

$$ \textrm{logit}(p_i) = \alpha_i $$

$$ \alpha_i = \textrm{Normal}(0, 1.5) $$

Lo cual se traduce en el siguiente código de Stan:

```{stan output.var="m_2"}
data {
  int<lower=0> T;             // Número de tanques
  int<lower=0> S[T];          // Número de sobrevivientes
  int<lower=0> D[T];          // Densidad inicial
}

parameters {
  real alpha[T];              // alpha para cada tanque
}

model {
  // Priors para cada alpha_i
  for (i in 1:T) {
    alpha[i] ~ normal(0, 1.5);
  }
  
  // Modelo para cada tanque
  for (t in 1:T) {
    S[t] ~ binomial(D[t], inv_logit(alpha[t]));
  }
}

generated quantities {
  int S_rep[T];

  // Generar predicciones 
  for (t in 1:T) {
    S_rep[t] = binomial_rng(D[t], inv_logit(alpha[t]));
  }
}

```

```{r ajuste_m2}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE

dat <- list(
  "T" = max(df$tank),
  S = df$surv,
  D = df$density
)

fit2 <- rstan::sampling(m_2, 
                 data = dat, 
                 iter = 1000, 
                 chains = 2, 
                 cores = 2,
                 refresh=0)
```

Podemos ver los resultados de nuestro segundo modelo para la estimación de $\alpha$.

```{r fit_m2}
#| echo: FALSE
#| warning: FALSE
#| message: FALSE

fit2_summary <- rstan::summary(fit2, 
                               probs = c(0.025,
                                         0.5,
                                         0.975),
                               pars=c('alpha','lp__'))$summary 

fit2_summary |> 
  as.data.frame() |>
  rownames_to_column("parameter") |>
  select(parameter,mean, sd, "2.5%", "50%", "97.5%", n_eff, Rhat) |>
  gt() |>
  fmt_number()
```

```{r predictions_m2}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE

post2 <- as.data.frame(fit2, pars = c('S_rep'))
df$urv_est2 <- post2 %>% colMeans
df$propsurv_est2 <- df$urv_est2/df$density

alpha2 <- as.data.frame(fit2, pars = c('alpha')) 
alpha_est2 <- alpha2$alpha %>% mean() %>% plogis

# Create the scatterplot with annotations
p <- ggplot(df, 
            aes(x = index, 
                y = propsurv_est2)) +
  geom_point(data=df, 
          aes(x = index, 
              y = propsurv), color='grey')+
  geom_point(color = 'red3') +
  geom_hline(yintercept = alpha_est, 
             linetype = "dashed", 
             color = "blue4") +
  # annotate("text", 
  #          x = max(df$index) - 23, 
  #          y = alpha_est + 0.05, 
  #          label = "Promedio de supervivencia en tanques", 
  #          color = "black", 
  #          fontface = "italic", 
  #          hjust = 0) +  
  labs(x = "Tanque", 
       y = "Tasa de Supervivencia") +
  theme(
    axis.title.x = element_text(face = "italic"),
    axis.title.y = element_text(face = "italic")
  ) +
  scale_x_continuous(breaks = c(8, 24, 40), 
                     labels = c("1 <= Pequeño < 16", 
                                "16 <= Mediano < 32", 
                                "32 <= Grande < 48")) +
  geom_vline(xintercept = 16, color = "cyan3")+
  geom_vline(xintercept = 32, color = "cyan3")+
  geom_vline(xintercept = 48, color = "cyan3")+
  # ylim(0, 1) +
  scale_y_continuous(labels = scales::percent_format())

p
```

## Modelo Parcialmente Agrupado

Pero igualmente se puede optar por un modelo parcialmente agrupado. En este caso, se agregan dos parámetros: $\bar{\alpha}$ y $\sigma$, los cuáles llamaremos hiperparámetros desde este punto. El punto es que, en el modelo anterior, todas las $\alpha_i$ se distribuían Normal con una media y desviación estándar establecida. Con esta modificación, los $\alpha_i$ comparten una misma distribución, lo que le permite transmitir información entre tanques al modelo.

El modelo se ve así:

$$ S_i \sim \textrm{Binomial}(D_i, p_i) $$

$$ \textrm{logit}(p_i) = \alpha_{\textrm{Tanque}[i]} $$

$$ \alpha_j \sim \textrm{Normal}(\mu, \sigma) $$

$$ \mu \sim \textrm{Normal}(0, 1.5) $$

$$ \sigma \sim \textrm{Exponential}(1) $$

Lo que se traduce en el siguiente código de Stan:

```{stan output.var="m_3"}
data {
  int<lower=0> T;         // Num de tanques
  int<lower=0> S[T];      // Num de renacuajos que sobrevivieron
  int<lower=0> D[T];      // Densidad inicial
}

parameters {
  real<lower=0> mu_alpha;        // Promedio del alpha
  real<lower=0> sigma_alpha;      // Desv est de los alphas
  vector[T] alpha_tank;           // Alpha de cada tanque
}

model {
  // Hyperpriors 
  mu_alpha ~ normal(0, 1.5);
  sigma_alpha ~ exponential(1);
  // Priors
  alpha_tank ~ normal(mu_alpha, sigma_alpha);

  for (t in 1:T) {
    S[t] ~ binomial(D[t], inv_logit(alpha_tank[t]));
  }
}

generated quantities {
  int S_rep[T]; 

  for (t in 1:T) {
    S_rep[t] = binomial_rng(D[t], inv_logit(alpha_tank[t]));
  }
}

```

```{r ajuste_m3}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE

dat <- list(
  "T" = max(df$tank),
  S = df$surv,
  D = df$density
)

fit3 <- rstan::sampling(m_3, 
                 data = dat, 
                 iter = 1000, 
                 chains = 2, 
                 cores = 2,
                 refresh=0)
```

```{r fit_m3}
#| echo: FALSE
#| warning: FALSE
#| message: FALSE

fit3_summary <- rstan::summary(fit3, 
                               probs = c(0.025,
                                         0.5,
                                         0.975),
                               pars=c('alpha_tank','lp__'))$summary 

fit3_summary |> 
  as.data.frame() |>
  rownames_to_column("parameter") |>
  select(parameter,mean, sd, "2.5%", "50%", "97.5%", n_eff, Rhat) |>
  gt() |>
  fmt_number()
```

Y para los hiperparámetros

```{r fit_m3_pt2}
#| echo: FALSE
#| warning: FALSE
#| message: FALSE

fit3_summary2 <- rstan::summary(fit3, 
                               probs = c(0.025,
                                         0.5,
                                         0.975),
                               pars=c('mu_alpha',
                                      'sigma_alpha'))$summary 

fit3_summary2 |> 
  as.data.frame() |>
  rownames_to_column("parameter") |>
  select(parameter,mean, sd, "2.5%", "50%", "97.5%", n_eff, Rhat) |>
  gt() |>
  fmt_number()
```

Y podemos, nuevamente, ver cómo se comportan nuestras predicciones contra los valores observados.

```{r predictions_m3}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE

post3 <- as.data.frame(fit3, pars = c('S_rep'))
df$urv_est3 <- post3 %>% colMeans
df$propsurv_est3 <- df$urv_est3/df$density

alpha3 <- as.data.frame(fit3, pars = c('alpha_tank')) 
alpha_est3 <- alpha3$alpha %>% mean() %>% plogis

# Create the scatterplot with annotations
p <- ggplot(df, 
            aes(x = index, 
                y = propsurv_est3)) +
  geom_point(data=df, 
          aes(x = index, 
              y = propsurv), color='grey')+
  geom_point(color = 'blue3') +
  geom_hline(yintercept = alpha_est, 
             linetype = "dashed", 
             color = "blue4") +
  labs(x = "Tanque", 
       y = "Tasa de Supervivencia") +
  theme(
    axis.title.x = element_text(face = "italic"),
    axis.title.y = element_text(face = "italic")
  ) +
  scale_x_continuous(breaks = c(8, 24, 40), 
                     labels = c("1 <= Pequeño < 16", 
                                "16 <= Mediano < 32", 
                                "32 <= Grande < 48")) +
  geom_vline(xintercept = 16, color = "cyan3")+
  geom_vline(xintercept = 32, color = "cyan3")+
  geom_vline(xintercept = 48, color = "cyan3")+
  # ylim(0, 1) +
  scale_y_continuous(labels = scales::percent_format())

p

```

## Comparativo

A simple vista, pareciera que el modelo sin agrupar y el modelo parcialmente agrupado (jerárquico) tienen comportamientos similares. Podemos graficar las estimaciones de una y otra para ver el comportamiento con mayor detenimiento.

```{r tablas_auxiliares}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE

aux <- post3 %>% 
  pivot_longer(cols=1:ncol(post3), 
               names_to="parameter", 
               values_to="value") %>%
  group_by(parameter) %>%
  summarise(m3_q2_5=quantile(value, probs = 0.025),
            m3_mean=mean(value, na.rm=T),
            m3_q97_5=quantile(value, probs = 0.975)) %>% 
  ungroup() %>% 
  mutate(index=as.numeric(gsub("[^0-9]", "", parameter))) %>%
  left_join(df %>% select(index, density), by="index") %>% 
  mutate(m3_lower = m3_q2_5/density, 
         m3_sup = m3_mean/density,
         m3_upper = m3_q97_5/density)

aux2 <- post2 %>% 
  pivot_longer(cols=1:ncol(post2), 
               names_to="parameter", 
               values_to="value") %>%
  group_by(parameter) %>% 
  summarise(m2_q2_5=quantile(value, probs = 0.025), 
            m2_mean=mean(value, na.rm=T),
            m2_q97_5=quantile(value, probs = 0.975)) %>% 
  ungroup() %>%
  mutate(index=as.numeric(gsub("[^0-9]", "", parameter))) %>%
  left_join(df %>% select(index, density), by="index") %>% 
  mutate(m2_lower = m2_q2_5/density,
         m2_sup = m2_mean/density,
         m2_upper = m2_q97_5/density)
```

```{r graficas_comparativo}
#| echo: FALSE
#| warning: FALSE
#| message: FALSE

p1<- ggplot(df, 
       aes(x = index, 
           y = propsurv_est3)) +
  geom_point(data=df, 
             aes(x = index, 
                 y = propsurv), color='grey')+
  geom_point(color = 'blue3') +
  geom_point(aes(x=index, y=propsurv_est2), color='red3') +
  geom_hline(yintercept = alpha_est, 
             linetype = "dashed", 
             color = "blue4") +
  labs(x = "Tanque", 
       y = "Tasa de Supervivencia",
       title="Comparativo entre modelos",
       subtitle="No agrupado = rojo, Jerárquico = azul") +
  theme(
    axis.title.x = element_text(face = "italic"),
    axis.title.y = element_text(face = "italic")) +
  scale_x_continuous(breaks = c(8, 24, 40), 
                     labels = c("1 <= Pequeño < 16", 
                                "16 <= Mediano < 32", 
                                "32 <= Grande < 48")) +
  geom_vline(xintercept = 15.5, color = "cyan3")+
  geom_vline(xintercept = 31.5, color = "cyan3")+
  geom_vline(xintercept = 48.5, color = "cyan3")+
  scale_y_continuous(labels = scales::percent_format())

p3 <- ggplot(df, 
       aes(x = index, 
           y = propsurv_est3)) +
  geom_point(data=df, 
             aes(x = index, 
                 y = propsurv), color='grey')+
  geom_point(color = 'blue3') +
  geom_segment(data=aux,
               aes(x = index,
                   xend = index,
                   y = m3_lower,,
                   yend = m3_upper),
               color = "blue", alpha=0.2, linewidth = 1) +
  geom_hline(yintercept = alpha_est, 
             linetype = "dashed", 
             color = "blue4") +
  labs(x = "Tanque", 
       y = "",
       title="Modelo jerárquico") +
  theme(
    axis.title.x = element_text(face = "italic"),
    axis.title.y = element_text(face = "italic")
  ) +
  scale_x_continuous(breaks = c(8, 24, 40), 
                     labels = c("1 <= Pequeño < 16", 
                                "16 <= Mediano < 32", 
                                "32 <= Grande < 48")) +
  geom_vline(xintercept = 15.5, color = "cyan3")+
  geom_vline(xintercept = 31.5, color = "cyan3")+
  geom_vline(xintercept = 48.5, color = "cyan3")+
  scale_y_continuous(labels = scales::percent_format())

p2 <- ggplot(df, 
       aes(x = index, 
           y = propsurv_est2)) +
  geom_point(data=df, 
             aes(x = index, 
                 y = propsurv), color='grey')+
  geom_point(color='red3') +
  geom_segment(data=aux2,
               aes(x = index,
                   xend = index,
                   y = m2_lower,,
                   yend = m2_upper),
               color = "red", alpha=0.2, linewidth = 1) +
  geom_hline(yintercept = alpha_est, 
             linetype = "dashed", 
             color = "blue4") +
  labs(x = "Tanque", 
       y = "Tasa de Supervivencia",
       title="Modelo no agrupado") +
  theme(
    axis.title.x = element_text(face = "italic"),
    axis.title.y = element_text(face = "italic")
  ) +
  scale_x_continuous(breaks = c(8, 24, 40), 
                     labels = c("1 <= Pequeño < 16", 
                                "16 <= Mediano < 32", 
                                "32 <= Grande < 48")) +
  geom_vline(xintercept = 15.5, color = "cyan3")+
  geom_vline(xintercept = 31.5, color = "cyan3")+
  geom_vline(xintercept = 48.5, color = "cyan3")+
  scale_y_continuous(labels = scales::percent_format())

p1
```

Pero podemos incluir intervalos de credibilidad para ver su comportamiento:

```{r graf_comp2}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE

(p2/p3)
```

## Modelo Completo

En los modelos anteriores no estamos incorporando todas las variables, y como lo que deseamos es estudiar el fenómeno, incluir todas las variables, dado nuestro DAG, puede mejorar la estimación de los efectos por variable. Podemos extender entonces la idea del Modelo Jerárquico e incorporar las otras variables. De tal modo que:

$$ S_i \sim \textrm{Binomial}(D_i, p_i) $$

$$ \textrm{logit}(p_i) = \alpha_{\textrm{Tanque}[i]} + \beta_p *\textrm{pred} + \beta_s *\textrm{size}$$

$$ \alpha_j \sim \textrm{Normal}(\mu, \sigma) $$

$$ \mu \sim \textrm{Normal}(0, 1.5) $$

$$ \sigma \sim \textrm{Exponential}(1) $$

$$
\beta_p \sim \textrm{Normal}(-0.5,1)
$$

$$
\beta_s \sim \textrm{Normal}(0,1)
$$

```{r preparando_df}
#| echo: FALSE 
#| warning: FALSE
#| message: FALSE

df <- df %>% 
  mutate(pred_num=ifelse(pred=='no',0,1),
         size_num=ifelse(size=='small',0,1)
         ) 
```

```{stan output.var="m_4"}
data {
  int<lower=0> N;               // Número total de observaciones
  int<lower=0> T;               // Número de tanques
  int<lower=0> surv[N];         // renacuajos que sobrevivieron
  int<lower=0> density[N];      // Densidad inicial de renacuajos
  int<lower=1, upper=T> tank[N];// Índice del número de tanque
  vector[N] pred;               // Presencia de depredadores (0 o 1)
  vector[N] size;               // Tamaño de los renacuajos
}

parameters {
  real<lower=0> mu_alpha;      // Promedio de alpha
  real<lower=0> sigma_alpha;    // Desviación estándar de los alphas
  vector[T] alpha_tank;         // Alpha para cada tanque
  real bp;                      // Coef para los depredadores
  real bs;                      // Coef del tamaño de los renacuajos
}

model {
  // Hyperpriors
  mu_alpha ~ normal(0, 1.5);
  sigma_alpha ~ exponential(1);

  // Priors
  alpha_tank ~ normal(mu_alpha, sigma_alpha);
  bp ~ normal(-0.5, 1);
  bs ~ normal(0, 1);  // Prior normal para el coeficiente de tamaño

  // Modelo para cada observación
  for (n in 1:N) {
    real p = inv_logit(alpha_tank[tank[n]] + bp * pred[n] + bs * size[n]);
    surv[n] ~ binomial(density[n], p);
  }
}

generated quantities {
  int surv_rep[N]; // Predicciones replicadas para la supervivencia

  for (n in 1:N) {
    surv_rep[n] = binomial_rng(density[n], inv_logit(alpha_tank[tank[n]] + bp * pred[n] + bs * size[n]));
  }
}

```

```{r ajuste_m4}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE

dat <- list(
  N = nrow(df),
  "T" = max(df$tank),
  surv = df$surv,
  density = df$density,
  tank = df$tank,
  pred = df$pred_num,
  size = df$size_num
)

fit4 <- rstan::sampling(m_4, 
                 data = dat, 
                 iter = 1000, 
                 chains = 2, 
                 cores = 2,
                 refresh=0)
```

```{r tabla_m4}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE

fit4_summary <- rstan::summary(fit4, 
                               probs = c(0.025,
                                         0.5,
                                         0.975),
                               pars=c('alpha_tank','lp__'))$summary 

fit4_summary |> 
  as.data.frame() |>
  rownames_to_column("parameter") |>
  select(parameter,mean, sd, "2.5%", "50%", "97.5%", n_eff, Rhat) |>
  gt() |>
  fmt_number()
```

```{r}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE

fit4_summary2 <- rstan::summary(fit4, 
                               probs = c(0.025,
                                         0.5,
                                         0.975),
                               pars=c('mu_alpha',
                                      'sigma_alpha',
                                      'bp',
                                      'bs'))$summary 

fit4_summary2 |> 
  as.data.frame() |>
  rownames_to_column("parameter") |>
  select(parameter,mean, sd, "2.5%", "50%", "97.5%", n_eff, Rhat) |>
  gt() |>
  fmt_number()
```

Y podemos ver el comparativo entre las predicciones y los datos reales:

```{r predictions_m4}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE

post4 <- as.data.frame(fit4, pars = c('surv_rep'))
df$urv_est4 <- post4 %>% colMeans
df$propsurv_est4 <- df$urv_est4/df$density

alpha4 <- as.data.frame(fit4, pars = c('alpha_tank')) 
alpha_est4 <- alpha4$alpha %>% mean() %>% plogis

# Create the scatterplot with annotations
p <- ggplot(df, 
            aes(x = index, 
                y = propsurv_est4)) +
  geom_point(data=df, 
          aes(x = index, 
              y = propsurv), color='grey')+
  geom_point(color = 'green3') +
  geom_hline(yintercept = alpha_est, 
             linetype = "dashed", 
             color = "blue4") +
  labs(x = "Tanque", 
       y = "Tasa de Supervivencia") +
  theme(
    axis.title.x = element_text(face = "italic"),
    axis.title.y = element_text(face = "italic")
  ) +
  scale_x_continuous(breaks = c(8, 24, 40), 
                     labels = c("1 <= Pequeño < 16", 
                                "16 <= Mediano < 32", 
                                "32 <= Grande < 48")) +
  geom_vline(xintercept = 16, color = "cyan3")+
  geom_vline(xintercept = 32, color = "cyan3")+
  geom_vline(xintercept = 48, color = "cyan3")+
  # ylim(0, 1) +
  scale_y_continuous(labels = scales::percent_format())

p

```

Y podemos repetir igualmente el ejercicio anterior para comparar entre modelos:

```{r tabla_aux4}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE

aux4 <- post4 %>% 
  pivot_longer(cols=1:ncol(post4), 
               names_to="parameter", 
               values_to="value") %>%
  group_by(parameter) %>%
  summarise(m4_q2_5=quantile(value, probs = 0.025),
            m4_mean=mean(value, na.rm=T),
            m4_q97_5=quantile(value, probs = 0.975)) %>% 
  ungroup() %>% 
  mutate(index=as.numeric(gsub("[^0-9]", "", parameter))) %>%
  left_join(df %>% select(index, density), by="index") %>% 
  mutate(m4_lower = m4_q2_5/density, 
         m4_sup = m4_mean/density,
         m4_upper = m4_q97_5/density)
```

```{r}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE
p1<- ggplot(df, 
       aes(x = index, 
           y = propsurv_est3)) +
  geom_point(data=df, 
             aes(x = index, 
                 y = propsurv), color='grey')+
  geom_point(color = 'blue3') +
  geom_point(aes(x=index, y=propsurv_est4), color='green3') +
  geom_hline(yintercept = alpha_est, 
             linetype = "dashed", 
             color = "blue4") +
  labs(x = "Tanque", 
       y = "Tasa de Supervivencia",
       title="Comparativo entre modelos",
       subtitle="Jerárquico = azul, Completo=verde") +
  theme(
    axis.title.x = element_text(face = "italic"),
    axis.title.y = element_text(face = "italic")) +
  scale_x_continuous(breaks = c(8, 24, 40), 
                     labels = c("1 <= Pequeño < 16", 
                                "16 <= Mediano < 32", 
                                "32 <= Grande < 48")) +
  geom_vline(xintercept = 15.5, color = "cyan3")+
  geom_vline(xintercept = 31.5, color = "cyan3")+
  geom_vline(xintercept = 48.5, color = "cyan3")+
  scale_y_continuous(labels = scales::percent_format())

p3 <- ggplot(df, 
       aes(x = index, 
           y = propsurv_est3)) +
  geom_point(data=df, 
             aes(x = index, 
                 y = propsurv), color='grey')+
  geom_point(color = 'blue3') +
  geom_segment(data=aux,
               aes(x = index,
                   xend = index,
                   y = m3_lower,,
                   yend = m3_upper),
               color = "blue", alpha=0.2, linewidth = 1) +
  geom_hline(yintercept = alpha_est, 
             linetype = "dashed", 
             color = "blue4") +
  labs(x = "Tanque", 
       y = "",
       title="Modelo jerárquico") +
  theme(
    axis.title.x = element_text(face = "italic"),
    axis.title.y = element_text(face = "italic")
  ) +
  scale_x_continuous(breaks = c(8, 24, 40), 
                     labels = c("1 <= Pequeño < 16", 
                                "16 <= Mediano < 32", 
                                "32 <= Grande < 48")) +
  geom_vline(xintercept = 15.5, color = "cyan3")+
  geom_vline(xintercept = 31.5, color = "cyan3")+
  geom_vline(xintercept = 48.5, color = "cyan3")+
  scale_y_continuous(labels = scales::percent_format())

p2 <- ggplot(df, 
       aes(x = index, 
           y = propsurv_est4)) +
  geom_point(data=df, 
             aes(x = index, 
                 y = propsurv), color='grey')+
  geom_point(color='green3') +
  geom_segment(data=aux4,
               aes(x = index,
                   xend = index,
                   y = m4_lower,,
                   yend = m4_upper),
               color = "green", alpha=0.2, linewidth = 1) +
  geom_hline(yintercept = alpha_est, 
             linetype = "dashed", 
             color = "blue4") +
  labs(x = "Tanque", 
       y = "Tasa de Supervivencia",
       title="Modelo completo") +
  theme(
    axis.title.x = element_text(face = "italic"),
    axis.title.y = element_text(face = "italic")
  ) +
  scale_x_continuous(breaks = c(8, 24, 40), 
                     labels = c("1 <= Pequeño < 16", 
                                "16 <= Mediano < 32", 
                                "32 <= Grande < 48")) +
  geom_vline(xintercept = 15.5, color = "cyan3")+
  geom_vline(xintercept = 31.5, color = "cyan3")+
  geom_vline(xintercept = 48.5, color = "cyan3")+
  scale_y_continuous(labels = scales::percent_format())

p1
```

```{r}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE
(p3/p2)
```

Y parece que algo empeoró en algunos casos, metimos más variables y parece que nos estamos alejando de los valores observados. Pero entendamos mejor qué está pasando

```{r graf_rectangles}
#| echo: FALSE
#| warning: FALSE
#| message: FALSE

p4 <- ggplot(df, 
       aes(x = index, 
           y = propsurv_est3)) +
  geom_rect(aes(xmin = 0, 
                         xmax = 8.5, 
                         ymin = 0, 
                         ymax = 1),
            fill = "lightblue", 
            alpha = 0.01)+
  geom_rect(aes(xmin = 16.5, 
                         xmax = 24.5, 
                         ymin = 0, 
                         ymax = 1),
            fill = "lightblue", 
            alpha = 0.01)+
  geom_rect(aes(xmin = 32.5, 
                         xmax = 40.5, 
                         ymin = 0, 
                         ymax = 1),
            fill = "lightblue", 
            alpha = 0.01)+
  geom_point(data=df, 
             aes(x = index, 
                 y = propsurv), color='grey')+
  geom_point(color = 'blue3') +
  geom_point(aes(x=index, y=propsurv_est4), color='green3') +
  geom_hline(yintercept = alpha_est, 
             linetype = "dashed", 
             color = "blue4") +
  labs(x = "Tanque", 
       y = "Tasa de Supervivencia",
       title="Comparativo entre modelos",
       subtitle="Jerárquico = azul, Completo=verde, Zonas coloreadas = no pred") +
  theme(
    axis.title.x = element_text(face = "italic"),
    axis.title.y = element_text(face = "italic")) +
  scale_x_continuous(breaks = c(8, 24, 40), 
                     labels = c("1 <= Pequeño < 16", 
                                "16 <= Mediano < 32", 
                                "32 <= Grande < 48")) +
  geom_vline(xintercept = 15.5, color = "cyan3")+
  geom_vline(xintercept = 31.5, color = "cyan3")+
  geom_vline(xintercept = 48.5, color = "cyan3")+
  scale_y_continuous(labels = scales::percent_format())

  

p4
```

Parece ser que en las aquellos tanques donde no hay presencia de depredadores (sombredos) nuestras predicciones se acercaron más a los valores observados, pero lo contrario pasa cuando hay presencia de depredadores.

## Diagnósticos

### Chequeos a priori

Para poner una inicial necesitamos conocimiento de dominio, sabemos que al estar hablando de un experimento controlado, diferente a una situación natural, los tanques no tienen más de 35 *reedfrogs*. Será extremo obtener una tasa de supervivencia menor al 3% (1 de los 35) y sabemos que puede existir valores por encima de 97% (34 de 35) sin embargo también se espera que no sean los más.

Proponemos nuestra propio modelo de optimización "valudación cruzada" para encontrar los hiperapriori

```{r}
set.seed(987)
p1_values <- seq(-3, 3, length.out = 100)  # media de alpha_bar
p2_values <- seq(0.1, 5, length.out = 100)  # desviación estándar de alpha_bar
p3_values <- seq(0.1, 5, length.out = 100)  # parámetro de sigma_alpha

inv_logit <- function(x) {
  1 / (1 + exp(-x))
}

evaluate_quartiles <- function(p1, p2, p3, n_sim = 10000) {
  alpha_bar <- rnorm(n_sim, p1, p2)
  sigma_alpha <- rexp(n_sim, rate = p3)
  alpha_tank <- rnorm(n_sim, alpha_bar, sigma_alpha)
  probabilities <- inv_logit(alpha_tank)
  q01 <- quantile(probabilities, 0.01)
  q99 <- quantile(probabilities, 0.99)
  return(c(q01, q99))
}

target_q01 <- 0.03
target_q99 <- 0.97

cost_function <- function(params) {
  p1 <- params[1]
  p2 <- params[2]
  p3 <- params[3]
  quartiles <- evaluate_quartiles(p1, p2, p3)
  q01 <- quartiles[1]
  q99 <- quartiles[2]
  return((q01 - target_q01)^2 + (q99 - target_q99)^2)
}

opt_results <- optimx(c(0, 1, 1), cost_function, 
                      lower = c(-3, 0.1, 0.1), 
                      upper = c(3, 5, 5), 
                      method = "L-BFGS-B")

par1 <- opt_results$p1
par2 <- opt_results$p2
par3 <- opt_results$p3
print(paste0("Parámetros de Miu: norm(",round(par1,2),",",round(par2,2),")"))
print(paste0("Parámetro de sigma: exp(",round(par3,2),")"))
```

```{r}
alpha_tank <- c()
prob_vector <- c()
for (i in 1:10000) {
  alpha_tank[i] = rnorm(1, rnorm(1,par1,par2), rexp(1,par3))
  prob_vector[i] = inv_logit(alpha_tank[i])
}
quantile(prob_vector, probs = c(0.01,0.02,0.03,0.97,0.98,0.99))
```

Ahora construimos nuestro modelo generativo y examinamos sus consecuencias. Simularemos 1500 repeticiones de las 48 observaciones que esperamos:

```{r}
T <- 48
D <- df$density
R <- 1500
sim_datos <- list(T = T, D = D)
```

```{r}
df_apriori <- c()
for (i in 1:R) {
  tanke <- c()
  density <- c()
  mu_alpha <- c()
  sigma_alpha <- c()
  alpha_tank <- c()
  survival_rate <- c()
  survival_abs <- c()
  for (j in 1:T) {
    tanke[j] = j
    density[j] = D[j]
    mu_alpha[j] = rnorm(1,par1,par2)
    sigma_alpha[j] = rexp(1,par3)
    alpha_tank[j] = rnorm(1,mu_alpha[j],sigma_alpha[j])
    survival_rate[j] = inv_logit(alpha_tank[j])
    survival_abs[j] = rbinom(1, density[j], survival_rate[j])
  }
  df_rep <- data.frame(
    tanke = tanke,
    density = density, 
    alpha_tank = alpha_tank,
    survival_rate = survival_rate, 
    survival_abs = survival_abs
  )
  df_apriori <- rbind(df_apriori, df_rep)
}
```

Simulamos de la apriori y algunas posibles configuraciones que esperaríamos ver. Hacen sentido? pareciera que sí, al compararlo los estanques grandes tienen tasas de supervivencia más bajas, lo que sin ver los datos podríamos suponer que esto permite que haya más depredadores por ejemplo. Aunque el modelo no tenga la variable, estos son muy útiles debido a que ya lleva el assumption de tener comportamientos diferentes por cada grupo. 

```{r}
df_apriori$draw <- rep(1:R, each = T)
a<-ggplot(df_apriori %>% filter(draw <= 5), aes(x = survival_rate)) +
  geom_histogram(bins = 30) +
  facet_wrap(~density) +
  labs(subtitle = "Simulaciones de observaciones a priori") +
  theme_bw()
a
```

```{r}
df_apriori <- dplyr::mutate(
  df_apriori, g_survival_rate = round(survival_rate,2))

ggplot(df_apriori |> group_by(draw, survival_abs) |> count() |> 
         group_by(survival_abs) |> 
         summarise(mediana = median(n), 
                   q_10 = quantile(n, 0.1), 
                   q90 = quantile(n, 0.9)) |> 
         pivot_longer(cols = c(mediana, q_10, q90), names_to = "tipo", values_to = "resumen"),
  aes(x = survival_abs)) +
  geom_line(aes(y = resumen, group = tipo)) +
  labs(subtitle = "Simulaciones de observaciones a priori")
```

Observamos que efectivamente que es **muy poco probable que haya tasas de supervivencia menores al 3% y mayores al 97%** y además está contenido dentro de los valores que tendrá el experimento (e.g, no más de 35 reed frogs)

```{r}
kable(df_apriori |> 
  mutate(menor_03 = survival_rate < 1/35, mayor_97 = survival_rate > 34/35) |> 
  summarise(menor_03 = mean(menor_03), mayor_97 = mean(mayor_97)))
```

## Chequeos posterior

```{stan output.var="posterior"}
data {
  int<lower=0> T;         // Num de tanques
  int<lower=0> S[T];      // Num de renacuajos que sobrevivieron
  int<lower=0> D[T];      // Densidad inicial
}

parameters {
  real<lower=0> alpha_bar;        // Promedio del alpha
  real<lower=0> sigma_alpha;      // Desv est de los alphas
  vector[T] alpha_tank;           // Alpha de cada tanque
}

model {
  // Hyperpriors 
  alpha_bar ~ normal(-0.02, 1.05);
  sigma_alpha ~ exponential(1.07);
  // Priors
  alpha_tank ~ normal(alpha_bar, sigma_alpha);

  for (t in 1:T) {
    S[t] ~ binomial(D[t], inv_logit(alpha_tank[t]));
  }
}

generated quantities {
  int S_rep[T]; 

  for (t in 1:T) {
    S_rep[t] = binomial_rng(D[t], inv_logit(alpha_tank[t]));
  }
}
```

```{r ajuste_posterior}
#| echo: FALSE
#| message: FALSE
#| warning: FALSE

dat <- list(
  "T" = max(df$tank),
  S = df$surv,
  D = df$density
)

fit_posterior <- rstan::sampling(posterior, 
                 data = dat, 
                 iter = 1500, 
                 chains = 2, 
                 cores = 2,
                 refresh=0)
```

Para considerar que estamos haciendo un modelo que aprenda de diferentes grupos las validaciones de la posterior las realizaremos por tamaño de tanque.

No hay un desajuste tan claro en el modelo para ninguno de los casos. Tal vez viéndolo a total podríamos regresar al análisis conceptual y determinar si hay algo en el proceso generador de datos que no estamos considerando. 

```{r}
sims_tbl  <- as.data.frame(fit_posterior, pars = c('S_rep'))

obs_post_tbl <-  sims_tbl |> 
  as_tibble() |>
  pivot_longer(cols = starts_with("S_rep"), 
               names_to = "y", 
               values_to = "valor") %>%
  separate(y, into = c("prefix", "tank"), sep = "\\[", remove = FALSE) %>%
  mutate(tank = as.numeric(gsub("\\]", "", tank)))


obs_post_tbl$draw <- rep(1:1500, each = 48)

obs_post_tbl <- 
  left_join(obs_post_tbl,
            df, by = "tank") %>%
  dplyr::mutate(., surv_rate = valor/density)
```

**TODOS**

```{r}
ggplot(obs_post_tbl |> 
         filter(draw <= 10) |>
         select(draw, surv_rate) |>
         bind_rows(df |> 
                     rename(surv_rate = propsurv) |>
                     mutate(draw = 11) |>
                     select(draw, surv_rate)), 
       aes(x = surv_rate)) +
  geom_histogram(bins = 10) +
  facet_wrap(~draw) + theme_bw()
```

**Primer tamaño**

```{r}
ggplot(obs_post_tbl |> 
         filter(draw <= 10, density == 10) |>
         select(draw, surv_rate) |>
         bind_rows(df |> 
                     filter(density == 10) |>
                     rename(surv_rate = propsurv) |>
                     mutate(draw = 11) |>
                     select(draw, surv_rate)), 
       aes(x = surv_rate)) +
  geom_histogram(bins = 10) +
  facet_wrap(~draw) + theme_bw()
```

```{r}
ggplot(obs_post_tbl |> 
         filter(draw <= 10, density == 25) |>
         select(draw, surv_rate) |>
         bind_rows(df |> 
                     filter(density == 25) |>
                     rename(surv_rate = propsurv) |>
                     mutate(draw = 11) |>
                     select(draw, surv_rate)), 
       aes(x = surv_rate)) +
  geom_histogram(bins = 10) +
  facet_wrap(~draw) + theme_bw()
```

```{r}
ggplot(obs_post_tbl |> 
         filter(draw <= 10, density == 35) |>
         select(draw, surv_rate) |>
         bind_rows(df |> 
                     filter(density == 35) |>
                     rename(surv_rate = propsurv) |>
                     mutate(draw = 11) |>
                     select(draw, surv_rate)), 
       aes(x = surv_rate)) +
  geom_histogram(bins = 10) +
  facet_wrap(~draw) + theme_bw()
```


## Anexos {#sec-anexos}

### Rethinking y sus datos {#sec-rethinking-y-sus-datos}

Para instalar la librería de *rethinking*, se pueden seguir las instrucciones del repositorio de McElreath, disponible en este [link](https://github.com/rmcelreath/rethinking "Repositorio de rethinking").

Una vez instalada la librería y sus dependencias, los datos de *reedfrogs* se pueden obtener corriendo el siguiente código

```{r anexo1_cargarDatos, eval=FALSE}
library(rethinking)
data(reedfrogs)
```
